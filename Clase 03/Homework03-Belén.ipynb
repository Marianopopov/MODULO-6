{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio:\n",
    "\n",
    "-Con la problemática anterior, construya una metodología la cual analice si realmente dicho modelo también sirve con datosque no fueron usados para ajustar el algoritmo.\n",
    "\n",
    "Tips: Recuerda el análisis de overfitting y underfitting visto en clase.\n",
    "\n",
    "Ahora, ya tenemos más herramientas de evaluación para analizar la effectividad del modelo.\n",
    "\n",
    "-Use las métricas de evaluación vistas en la clase de hoy y anteriores, para sacar más conclusiones sobre la efectividad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('conversiones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Conversion\"] = pd.Categorical(data[\"Conversion\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Conversion\"]\n",
    "X = data.drop([\"Conversion\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.98\n",
      "Precisión: [0.99294974 0.95859805]\n",
      "Sensibilidad: [0.95694649 0.99322996]\n",
      "F1Score: [0.97461573 0.97560677]\n",
      "Matriz de Confusión: [[30562  1375]\n",
      " [  217 31836]]\n"
     ]
    }
   ],
   "source": [
    "#División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "knn_modelo = KNeighborsClassifier(n_neighbors=3)  # Se ajustó el hiperparámetro a 3\n",
    "knn_modelo.fit(X_train, y_train)\n",
    "\n",
    "#Predicción en el conjunto de testeo\n",
    "y_pred = knn_modelo.predict(X_test)\n",
    "\n",
    "#Evaluación del rendimiento con la exactitud\n",
    "Exactitud = accuracy_score(y_test, y_pred)\n",
    "print(f'Exactitud: {Exactitud:.2f}')\n",
    "\n",
    "#Evaluación del rendimiento con Precisión\n",
    "Precision = precision_score(y_test, y_pred, average= None)\n",
    "print('Precisión:', Precision)\n",
    "\n",
    "#Evaluación del rendimiento con Recall \n",
    "Sensibilidad = recall_score(y_test, y_pred, average= None)\n",
    "print('Sensibilidad:',Sensibilidad)\n",
    "\n",
    "#Evaluación del rendimiento con F1-Score\n",
    "F1S = f1_score(y_test, y_pred, average= None)\n",
    "print('F1Score:', F1S)\n",
    "\n",
    "#Evaluación del rendimiento con Matriz de Confusión\n",
    "Matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:', Matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63990"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intepretación de la matriz de Confusión \n",
    "\n",
    "El modelo clasificó correctamente 30562 instancias como negativas (TN).\n",
    "\n",
    "El modelo cometió 1375 falsas alarmas, es decir, clasificó erróneamente 1,375 instancias como positivas cuando en realidad eran negativas (FP).\n",
    "\n",
    "El modelo omitió 217 instancias que eran positivas y las clasificó incorrectamente como negativas (FN).\n",
    "\n",
    "El modelo clasificó correctamente 31.836 instancias como positivas (TP)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
